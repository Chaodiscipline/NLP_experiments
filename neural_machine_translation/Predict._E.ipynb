{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import jieba\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tensorflow.python.layers import core as layers_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入\n",
    "def data_preprocess(path):\n",
    "    corpus_en = [] \n",
    "    with open(path, 'r',encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f): # i从0开始\n",
    "            line = line.strip()\n",
    "            corpus_en.append(line)\n",
    "                \n",
    "    return corpus_en\n",
    "\n",
    "# 分词\n",
    "def segment(corpus, tokenizer):\n",
    "    tokenized_corpus = []\n",
    "    tokenized_corpus = ' '.join([_ for _ in tokenizer(corpus) if _.strip(' ')])\n",
    "    tokenized_corpus = tokenized_corpus.split(' \\n ')\n",
    "    return tokenized_corpus\n",
    "\n",
    " \n",
    "\n",
    "# 把数据中的字/词转成对应id\n",
    "def transform(data, word2id):\n",
    "    ret_data = []\n",
    "    for sentence in data:\n",
    "        ret_data.append([word2id.get(word, 1) for word in sentence.split()]) # word2id.get(word, 1) 如果word不在字典中，则返回默认值1\n",
    "    return ret_data\n",
    "\n",
    "# padding  对长度小于max的以0填充，大于的截断\n",
    "def padding(data, max_len):\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(data, max_len, padding='post', truncating='post')\n",
    "\n",
    "def transform2word(data, id2word):\n",
    "    \"\"\"\n",
    "    把id转成word\n",
    "    \"\"\"\n",
    "    ret_data = []\n",
    "    for sentence in data:\n",
    "        ret_data.append(''.join([id2word.get(word, '<UNK>') for word in sentence]))\n",
    "    return ret_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTModel(object):\n",
    "    \"\"\"\n",
    "    带Attention的NMT模型\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 src_max_vocab_size, \n",
    "                 tgt_max_vocab_size, \n",
    "                 embedding_size,\n",
    "                 hidden_size,\n",
    "                 src_max_seq_len,\n",
    "                 tgt_max_seq_len,\n",
    "                 tgt_start_id,\n",
    "                 tgt_end_id,\n",
    "                 max_gradient_norm=5,\n",
    "                 maximum_iterations=None,\n",
    "                 optimizer='adam',\n",
    "                 ):\n",
    "        self.initializer = tf.random_uniform_initializer(\n",
    "        -0.05, 0.05)\n",
    "        self.optimizer = optimizer\n",
    "        # 源词表大小\n",
    "        self.src_max_vocab_size = src_max_vocab_size\n",
    "        # 目标词表大小\n",
    "        self.tgt_max_vocab_size = tgt_max_vocab_size\n",
    "        # 输入embedding大小（src与tgt的embedding_size可以不同）\n",
    "        self.embedding_size = embedding_size\n",
    "        # 隐层大小\n",
    "        self.hidden_size = hidden_size\n",
    "        # 源序列长度\n",
    "        self.src_max_seq_len = src_max_seq_len\n",
    "        # 目标序列长度\n",
    "        self.tgt_max_seq_len = tgt_max_seq_len\n",
    "        # 目标序列起始id（输入的初始id值）\n",
    "        self.tgt_start_id = tgt_start_id\n",
    "        # 目标的终结id（模型预测到该id后停止预测）\n",
    "        self.tgt_end_id = tgt_end_id\n",
    "        if maximum_iterations is None:\n",
    "            self.maximum_iterations = self.tgt_max_seq_len                                  # !!!!!!!!!!!\n",
    "        else:\n",
    "            self.maximum_iterations = maximum_iterations\n",
    "        self.max_gradient_norm = max_gradient_norm\n",
    "        self.add_placeholders()\n",
    "        self.batch_size = tf.shape(self.X)[0]\n",
    "        self.add_embeddings()\n",
    "        self.encoder()\n",
    "        self.decoder()\n",
    "        self.add_loss()\n",
    "        self.add_train_op()\n",
    "\n",
    "    def add_placeholders(self):\n",
    "        # X, Y_out, Y_in, X_len, Y_in_len, Y_out_len\n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y_out = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y_in = tf.placeholder(tf.int32, [None, None])\n",
    "        self.X_len = tf.placeholder(tf.int32, [None, ])\n",
    "        self.Y_in_len = tf.placeholder(tf.int32, [None, ])\n",
    "        self.Y_out_len = tf.placeholder(tf.int32, [None, ])\n",
    "        self.lr = tf.placeholder(tf.float32)\n",
    "        self.dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "    def add_embeddings(self):\n",
    "        with tf.variable_scope('embeddings', initializer=self.initializer):\n",
    "            # 创建变量\n",
    "            self.X_emb = tf.get_variable('X_emb', \n",
    "                shape=(self.src_max_vocab_size, self.embedding_size), \n",
    "                dtype=tf.float32)\n",
    "            self.Y_emb = tf.get_variable('Y_emb', \n",
    "                shape=(self.tgt_max_vocab_size, self.embedding_size), \n",
    "                dtype=tf.float32)\n",
    "\n",
    "            self.encoder_input = tf.nn.embedding_lookup(self.X_emb, self.X)\n",
    "            self.decoder_input = tf.nn.embedding_lookup(self.Y_emb, self.Y_in)\n",
    "\n",
    "    def encoder(self):\n",
    "        with tf.variable_scope('encoder'):\n",
    "            fw_encoder_cell = tf.contrib.rnn.GRUCell(self.hidden_size)\n",
    "            fw_encoder_cell = tf.contrib.rnn.DropoutWrapper(fw_encoder_cell, input_keep_prob=1-self.dropout)\n",
    "            bw_encoder_cell = tf.contrib.rnn.GRUCell(self.hidden_size)\n",
    "            bw_encoder_cell = tf.contrib.rnn.DropoutWrapper(bw_encoder_cell, input_keep_prob=1-self.dropout)\n",
    "\n",
    "            # 双向RNN\n",
    "            encoder_outputs, bi_last_state = tf.nn.bidirectional_dynamic_rnn(     \n",
    "                    fw_encoder_cell, bw_encoder_cell, self.encoder_input, \n",
    "                    self.X_len, dtype=tf.float32)\n",
    "            self.encoder_outputs = tf.concat(encoder_outputs, axis=-1)\n",
    "            self.encoder_last_state = bi_last_state\n",
    "\n",
    "\n",
    "    def decoder(self):\n",
    "        with tf.variable_scope('decoder'):\n",
    "            decoder_cell = tf.contrib.rnn.GRUCell(self.hidden_size)\n",
    "            decoder_cell = tf.contrib.rnn.DropoutWrapper(decoder_cell, input_keep_prob=1-self.dropout)\n",
    "            attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "                                    self.hidden_size, self.encoder_outputs,\n",
    "                                    memory_sequence_length=self.X_len)\n",
    "            decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                                    decoder_cell, attention_mechanism,\n",
    "                                    attention_layer_size=self.hidden_size)\n",
    "\n",
    "            projection_layer = layers_core.Dense(\n",
    "            self.tgt_max_vocab_size, use_bias=False)\n",
    "\n",
    "        # 训练或评估的时候，decoder的output是真实的target，input是target右移一个词\n",
    "        with tf.variable_scope('dynamic_decode'):\n",
    "            # Helper\n",
    "            helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                self.decoder_input, tf.ones((self.batch_size, ), dtype=tf.int32) * self.tgt_max_seq_len, time_major=False)\n",
    "            # Decoder\n",
    "            decoder_initial_state = decoder_cell.zero_state(self.batch_size, dtype=tf.float32).clone(\n",
    "                cell_state=self.encoder_last_state[0])\n",
    "            decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                decoder_cell, helper, decoder_initial_state,\n",
    "                output_layer=projection_layer)\n",
    "            # Dynamic decoding\n",
    "            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "            self.logits = outputs.rnn_output\n",
    "            self.pred = tf.argmax(self.logits, axis=2)\n",
    "\n",
    "        # 预测的时候，decoder的每个timestep的输入为前一个时刻的输出\n",
    "        with tf.variable_scope('dynamic_decode', reuse=True):\n",
    "            # Helper\n",
    "            helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                self.Y_emb,\n",
    "                start_tokens=tf.fill([self.batch_size], self.tgt_start_id),\n",
    "                end_token=self.tgt_end_id)\n",
    "            decoder_initial_state = decoder_cell.zero_state(self.batch_size, dtype=tf.float32).clone(\n",
    "                cell_state=self.encoder_last_state[0])\n",
    "            # Decoder\n",
    "            decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                decoder_cell, helper, decoder_initial_state,\n",
    "                output_layer=projection_layer)\n",
    "            # Dynamic decoding\n",
    "            outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder, maximum_iterations=self.maximum_iterations)                      # !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            self.translations = outputs.sample_id\n",
    "            \n",
    "    def add_loss(self): # 交叉熵\n",
    "        target_weights = tf.sequence_mask(\n",
    "                         self.Y_out_len, self.tgt_max_seq_len, dtype=self.logits.dtype)\n",
    "        crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                         labels=self.Y_out, logits=self.logits)\n",
    "        self.loss_op = (tf.reduce_sum(crossent * target_weights) / tf.to_float(self.batch_size))\n",
    "\n",
    "    def add_train_op(self):   # 优化器\n",
    "        params = tf.trainable_variables()\n",
    "        gradients = tf.gradients(self.loss_op, params)\n",
    "        clipped_gradients, _ = tf.clip_by_global_norm(\n",
    "            gradients, self.max_gradient_norm)\n",
    "        # Optimization\n",
    "        if self.optimizer == 'sgd':\n",
    "            optimizer = tf.train.GradientDescentOptimizer(self.lr)\n",
    "        elif self.optimizer == 'adadelta':\n",
    "            optimizer = tf.train.AdaDeltaOptimizer(self.lr)\n",
    "        else:\n",
    "            optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        self.train_op = optimizer.apply_gradients(\n",
    "            zip(clipped_gradients, params), global_step=self.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一些模型对应的参数\n",
    "optimizer = 'adam'\n",
    "lr = 1e-3\n",
    "# 55379\n",
    "# 4844\n",
    "src_max_vocab_size = 60004\n",
    "tgt_max_vocab_size = 7027\n",
    "embedding_size = 128\n",
    "hidden_size = 256\n",
    "src_max_seq_len = 40     # 源句的裁剪长度\n",
    "tgt_max_seq_len = 40       # 目标句的裁剪长度\n",
    "tgt_start_id = 2 # <S> \n",
    "tgt_end_id = 0 # <PAD>\n",
    "max_gradient_norm = 1.\n",
    "maximum_iterations = 70  #!!!    目标句 测试或验证 的翻译长度\n",
    "cf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "cf.gpu_options.per_process_gpu_memory_fraction = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    with open(r'C:\\Users\\19843\\Desktop\\natural_language_processing\\NMT\\data\\data_edu\\vocab_dict_and_corpus_biEduNew.pkl', 'rb') as fr:\n",
    "        en_word2id, en_id2word, ch_word2id, ch_id2word, __, __, __, __ = pkl.load(fr)\n",
    "    if type(X) == str:\n",
    "        X = X\n",
    "    elif type(X) == list or type(X) == tuple:\n",
    "        X = '\\n'.join(X)\n",
    "    else:\n",
    "        raise ValueError('You must ensure the `X` be string or list!')\n",
    "    X = segment(X, jieba.cut)\n",
    "    X = transform(X, en_word2id)\n",
    "    X = padding(X, src_max_seq_len)\n",
    "    X_len = np.sum((X > 0), axis=1)\n",
    "    # X -> (src_max_seq_len, ) or (batch, sec_max_seq_len, )\n",
    "    with tf.Session(config=cf) as sess:\n",
    "        model = NMTModel(src_max_vocab_size=src_max_vocab_size, \n",
    "                             tgt_max_vocab_size=tgt_max_vocab_size, \n",
    "                             embedding_size=embedding_size,\n",
    "                             hidden_size=hidden_size,\n",
    "                             src_max_seq_len=src_max_seq_len,\n",
    "                             tgt_max_seq_len=tgt_max_seq_len,\n",
    "                             tgt_start_id=tgt_start_id,\n",
    "                             tgt_end_id=tgt_end_id,\n",
    "                             max_gradient_norm=max_gradient_norm,\n",
    "                             maximum_iterations=maximum_iterations,\n",
    "                             optimizer=optimizer)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(r'C:\\Users\\19843\\Desktop\\natural_language_processing\\NMT\\model\\fromEdu'))\n",
    "        \n",
    "        translations = sess.run(model.translations, \n",
    "                            feed_dict={ model.X:X,\n",
    "                                        model.Y_out:[[]],\n",
    "                                        model.Y_in:[[]], \n",
    "                                        model.X_len:X_len,\n",
    "                                        model.Y_in_len:[],\n",
    "                                        model.Y_out_len:[],\n",
    "                                        model.lr:lr,\n",
    "                                        model.dropout:0.})\n",
    "        translations = transform2word(translations, ch_id2word)\n",
    "    return translations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\19843\\Desktop\\natural_language_processing\\NMT\\model\\fromEdu\\my_model-76494\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# t1 = time.time()\n",
    "testPath = r'finalTest\\toTest.txt'\n",
    "test_en = data_preprocess(testPath)\n",
    "\n",
    "def predict_wN(test_en_wN):\n",
    "    tf.reset_default_graph()\n",
    "    pred = predict(test_en_wN)\n",
    "    print(len(pred))\n",
    "    # 后处理，去除padding等\n",
    "    for i in range(len(pred)):\n",
    "        pred[i] = pred[i][:pred[i].find('<PAD>')]\n",
    "    # t2 = time.time()\n",
    "    # print(t2 - t1)\n",
    "    return pred\n",
    "\n",
    "# write \n",
    "pred = '\\n'.join(predict_wN(test_en))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pred.replace('\\u2022','')\n",
    "pred=pred.replace('\\xab','')\n",
    "pred=pred.replace('\\ufffd','')\n",
    "pred=pred.replace('\\u2219','')\n",
    "with open(r'finalTest\\pred5.txt', 'w') as f:\n",
    "    f.write(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\19843\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.979 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-6-0c2212708a03>:76: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-0c2212708a03>:84: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-6-0c2212708a03>:142: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from good_model/40_40_40_12/my_model-45240\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(64, 384), b.shape=(384, 512), m=64, n=512, k=384\n\t [[node encoder/bidirectional_rnn/fw/fw/while/gru_cell/MatMul (defined at <ipython-input-6-0c2212708a03>:84) ]]\n\t [[node dynamic_decode_1/decoder/while/Identity (defined at <ipython-input-6-0c2212708a03>:134) ]]\n\nCaused by op 'encoder/bidirectional_rnn/fw/fw/while/gru_cell/MatMul', defined at:\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-26082b34bc1a>\", line 20, in <module>\n    pred.append(predict_wN(test_en[i*64:(i+1)*64]))\n  File \"<ipython-input-12-26082b34bc1a>\", line 9, in predict_wN\n    pred = predict(test_en_wN)\n  File \"<ipython-input-7-50718c495839>\", line 26, in predict\n    optimizer=optimizer)\n  File \"<ipython-input-6-0c2212708a03>\", line 45, in __init__\n    self.encoder()\n  File \"<ipython-input-6-0c2212708a03>\", line 84, in encoder\n    self.X_len, dtype=tf.float32)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 443, in bidirectional_dynamic_rnn\n    time_major=time_major, scope=fw_scope)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 671, in dynamic_rnn\n    dtype=dtype)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 879, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3556, in while_loop\n    return_same_structure)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3087, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3022, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3525, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 845, in _time_step\n    skip_conditionals=True)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 276, in _rnn_step\n    new_output, new_state = call_cell()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 833, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 1284, in __call__\n    output, new_state = self._cell(inputs, state, scope=scope)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 371, in __call__\n    *args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 565, in call\n    array_ops.concat([inputs, state], 1), self._gate_kernel)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2455, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 5333, in mat_mul\n    name=name)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(64, 384), b.shape=(384, 512), m=64, n=512, k=384\n\t [[node encoder/bidirectional_rnn/fw/fw/while/gru_cell/MatMul (defined at <ipython-input-6-0c2212708a03>:84) ]]\n\t [[node dynamic_decode_1/decoder/while/Identity (defined at <ipython-input-6-0c2212708a03>:134) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(64, 384), b.shape=(384, 512), m=64, n=512, k=384\n\t [[{{node encoder/bidirectional_rnn/fw/fw/while/gru_cell/MatMul}}]]\n\t [[{{node dynamic_decode_1/decoder/while/Identity}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-26082b34bc1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_wN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_en\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_wN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_en\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-26082b34bc1a>\u001b[0m in \u001b[0;36mpredict_wN\u001b[1;34m(test_en_wN)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_wN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_en_wN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_en_wN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m# 后处理，去除padding等\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-50718c495839>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     36\u001b[0m                                         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_out_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                                         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                                         model.dropout:0.})\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mtranslations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform2word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch_id2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtranslations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(64, 384), b.shape=(384, 512), m=64, n=512, k=384\n\t [[node encoder/bidirectional_rnn/fw/fw/while/gru_cell/MatMul (defined at <ipython-input-6-0c2212708a03>:84) ]]\n\t [[node dynamic_decode_1/decoder/while/Identity (defined at <ipython-input-6-0c2212708a03>:134) ]]\n\nCaused by op 'encoder/bidirectional_rnn/fw/fw/while/gru_cell/MatMul', defined at:\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-26082b34bc1a>\", line 20, in <module>\n    pred.append(predict_wN(test_en[i*64:(i+1)*64]))\n  File \"<ipython-input-12-26082b34bc1a>\", line 9, in predict_wN\n    pred = predict(test_en_wN)\n  File \"<ipython-input-7-50718c495839>\", line 26, in predict\n    optimizer=optimizer)\n  File \"<ipython-input-6-0c2212708a03>\", line 45, in __init__\n    self.encoder()\n  File \"<ipython-input-6-0c2212708a03>\", line 84, in encoder\n    self.X_len, dtype=tf.float32)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 443, in bidirectional_dynamic_rnn\n    time_major=time_major, scope=fw_scope)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 671, in dynamic_rnn\n    dtype=dtype)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 879, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3556, in while_loop\n    return_same_structure)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3087, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3022, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3525, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 845, in _time_step\n    skip_conditionals=True)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 276, in _rnn_step\n    new_output, new_state = call_cell()\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 833, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 1284, in __call__\n    output, new_state = self._cell(inputs, state, scope=scope)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 371, in __call__\n    *args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 565, in call\n    array_ops.concat([inputs, state], 1), self._gate_kernel)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2455, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 5333, in mat_mul\n    name=name)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\19843\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(64, 384), b.shape=(384, 512), m=64, n=512, k=384\n\t [[node encoder/bidirectional_rnn/fw/fw/while/gru_cell/MatMul (defined at <ipython-input-6-0c2212708a03>:84) ]]\n\t [[node dynamic_decode_1/decoder/while/Identity (defined at <ipython-input-6-0c2212708a03>:134) ]]\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# t1 = time.time()\n",
    "testPath = r'validTest\\toTest.txt'\n",
    "test_en = data_preprocess(testPath)\n",
    "iteration = len(test_en)//64+1\n",
    "\n",
    "def predict_wN(test_en_wN):\n",
    "    tf.reset_default_graph()\n",
    "    pred = predict(test_en_wN)\n",
    "    # 后处理，去除padding等\n",
    "    for i in range(len(pred)):\n",
    "        pred[i] = pred[i][:pred[i].find('<PAD>')]\n",
    "    # t2 = time.time()\n",
    "    # print(t2 - t1)\n",
    "    return pred\n",
    "\n",
    "pred = []\n",
    "for i in range(iteration):\n",
    "    if i != iteration:\n",
    "        pred.append(predict_wN(test_en[i*64:(i+1)*64]))\n",
    "    else:\n",
    "        pred.append(predict_wN(test_en[i*64:]))\n",
    "\n",
    "\n",
    "# write \n",
    "pred = '\\n'.join(pred)\n",
    "with open(r'validTest\\pred1.txt', 'w') as f:\n",
    "    f.write(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 404.38922199999996,
   "position": {
    "height": "40px",
    "left": "1116.2px",
    "right": "20px",
    "top": "69px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
