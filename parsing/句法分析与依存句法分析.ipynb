{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 句法分析&依存句法分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 英文文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\19843\\Desktop\\natural_language_processing\\Experiment4\\english_sen.txt') as  f:\n",
    "    engtext = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constituency Parsing: (ROOT\n",
      "  (S\n",
      "    (NP (NN Nothing))\n",
      "    (VP (VBZ is)\n",
      "      (ADJP (JJ impossible)\n",
      "        (PP (TO to)\n",
      "          (NP (DT a) (JJ willing) (NN heart)))))\n",
      "    (. .)))\n",
      "\n",
      "Dependency Parsing: [('ROOT', 0, 3), ('nsubj', 3, 1), ('cop', 3, 2), ('case', 7, 4), ('det', 7, 5), ('amod', 7, 6), ('nmod', 3, 7), ('punct', 3, 8), ('ROOT', 0, 11), ('case', 5, 1), ('case', 5, 2), ('compound', 5, 3), ('compound', 5, 4), ('advcl', 11, 5), ('punct', 11, 6), ('csubj', 11, 7), ('dobj', 7, 8), ('cop', 11, 9), ('advmod', 11, 10), ('punct', 11, 12), ('ROOT', 0, 3), ('amod', 2, 1), ('nsubj', 3, 2), ('case', 5, 4), ('nmod', 9, 5), ('punct', 9, 6), ('amod', 8, 7), ('nsubj', 9, 8), ('ccomp', 3, 9), ('case', 11, 10), ('nmod', 9, 11), ('punct', 3, 12)]\n"
     ]
    }
   ],
   "source": [
    "# Simple usage\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = StanfordCoreNLP(r'C:\\Users\\19843\\Desktop\\natural_language_processing\\stanford-corenlp-full-2018-10-05')\n",
    "print('Constituency Parsing:\\n', nlp.parse(engtext))  #句法分析\n",
    "print('\\nDependency Parsing:\\n', nlp.dependency_parse(engtext))  #依存句法分析\n",
    "\n",
    "nlp.close() # Do not forget to close! The backend server will consume a lot memery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\19843\\Desktop\\natural_language_processing\\Experiment4\\chinese_sen.txt') as  f:\n",
    "    chitext = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constituency Parsing: (ROOT\n",
      "  (IP\n",
      "    (IP\n",
      "      (LCP\n",
      "        (IP\n",
      "          (NP (NN 学历))\n",
      "          (VP (VV 造假)\n",
      "            (NP\n",
      "              (NP (NN 风波))\n",
      "              (QP (CD 一))\n",
      "              (NP (NN 月)))))\n",
      "        (LC 后))\n",
      "      (PU ，)\n",
      "      (VP (VV 翟天)\n",
      "        (IP\n",
      "          (VP (VV 临)\n",
      "            (IP\n",
      "              (VP\n",
      "                (VP\n",
      "                  (PP (P 与)\n",
      "                    (NP (NR 辛芷蕾)))\n",
      "                  (VP (VV 牵)\n",
      "                    (NP (NN 手))))\n",
      "                (VP (VV 回家)))))))\n",
      "      (PU 。)\n",
      "      (IP\n",
      "        (NP\n",
      "          (ADJP (JJ 武磊))\n",
      "          (NP (NN 替补)))\n",
      "        (VP (VV 登场))))\n",
      "    (PU ，)\n",
      "    (IP\n",
      "      (NP (NR 梅西独) (NR 中))\n",
      "      (QP (CD 两)\n",
      "        (CLP (M 元)))\n",
      "      (VP\n",
      "        (VP (VV 助)\n",
      "          (NP (NR 巴萨))\n",
      "          (QP (CD 2:0)))\n",
      "        (VP (VV 战胜)\n",
      "          (NP (NN 西班牙人)))))\n",
      "    (PU 。)\n",
      "    (IP\n",
      "      (NP (NN 漫威) (NN 影业) (NN 官方) (NN 微博))\n",
      "      (VP (VV 宣布)\n",
      "        (IP\n",
      "          (NP (PU 《) (NN 复仇者) (NN 联盟4) (PU 》))\n",
      "          (VP\n",
      "            (ADVP (AD 正式))\n",
      "            (VP (VV 定)\n",
      "              (IP\n",
      "                (NP (NN 档))\n",
      "                (VP\n",
      "                  (NP (NT 4月) (NT 24日))\n",
      "                  (PP (P 在)\n",
      "                    (NP (NN 内地)))\n",
      "                  (VP (VV 上映)))))))))\n",
      "    (PU 。)\n",
      "    (IP\n",
      "      (NP (NT 3月) (NT 29日) (NT 下午))\n",
      "      (PU ，)\n",
      "      (NP\n",
      "        (CP\n",
      "          (IP\n",
      "            (NP (NN 呼声))\n",
      "            (VP\n",
      "              (ADVP (AD 极))\n",
      "              (VP (VA 高))))\n",
      "          (DEC 的))\n",
      "        (NP\n",
      "          (ADJP (JJ 人工))\n",
      "          (NP (NN 智能)))\n",
      "        (NP (NN 专业)))\n",
      "      (VP (SB 被)\n",
      "        (VP (VV 列入)\n",
      "          (IP\n",
      "            (VP (VV 新增)\n",
      "              (IP\n",
      "                (VP (VV 审批)\n",
      "                  (NP (NN 本科) (NN 专业) (NN 名单)))))))))\n",
      "    (PU ，)\n",
      "    (IP\n",
      "      (NP\n",
      "        (DP (DT 全))\n",
      "        (NP (NN 国)))\n",
      "      (VP\n",
      "        (ADVP (AD 共))\n",
      "        (VP (VE 有)\n",
      "          (IP\n",
      "            (NP\n",
      "              (QP (CD 35)\n",
      "                (CLP (M 所)))\n",
      "              (NP (NN 高校)))\n",
      "            (VP (VV 获)\n",
      "              (NP\n",
      "                (QP (OD 首)\n",
      "                  (CLP (M 批)))\n",
      "                (NP (NN 建设) (NN 资格))))))))\n",
      "    (PU 。)\n",
      "    (IP\n",
      "      (NP (NN ACM))\n",
      "      (VP (VV 宣布) (PU ，)\n",
      "        (IP\n",
      "          (NP\n",
      "            (NP\n",
      "              (DNP\n",
      "                (NP\n",
      "                  (ADJP (JJ 深度))\n",
      "                  (NP (NN 学习)))\n",
      "                (DEG 的))\n",
      "              (QP (CD 三)\n",
      "                (CLP (M 位)))\n",
      "              (NP (NN 创造者)))\n",
      "            (NP (NR Yoshua) (NR Bengio)))\n",
      "          (PU ，)\n",
      "          (NP\n",
      "            (NP (NR Yann) (NR LeCun))\n",
      "            (PU ，)\n",
      "            (CC 以及)\n",
      "            (NP (NR Geoffrey) (NR Hinton)))\n",
      "          (VP (VV 获得) (AS 了)\n",
      "            (NP\n",
      "              (DNP\n",
      "                (NP (NT 2019年))\n",
      "                (DEG 的))\n",
      "              (NP (NN 图灵奖)))))))\n",
      "    (PU 。)))\n",
      "\n",
      "Dependency Parsing: [('ROOT', 0, 2), ('nsubj', 2, 1), ('nsubj', 18, 3), ('dep', 5, 4), ('advmod:loc', 18, 5), ('case', 5, 6), ('punct', 18, 7), ('dep', 18, 8), ('ccomp', 8, 9), ('case', 11, 10), ('nmod:prep', 12, 11), ('conj', 9, 12), ('dobj', 12, 13), ('conj', 12, 14), ('punct', 18, 15), ('amod', 17, 16), ('nsubj', 18, 17), ('ccomp', 2, 18), ('punct', 2, 19), ('name', 21, 20), ('nsubj', 24, 21), ('dep', 24, 22), ('mark:clf', 22, 23), ('conj', 2, 24), ('dobj', 24, 25), ('nsubj', 27, 26), ('conj', 24, 27), ('dobj', 27, 28), ('punct', 2, 29), ('compound:nn', 31, 30), ('compound:nn', 33, 31), ('compound:nn', 33, 32), ('nsubj', 34, 33), ('conj', 2, 34), ('punct', 37, 35), ('compound:nn', 37, 36), ('nsubj', 40, 37), ('punct', 37, 38), ('advmod', 40, 39), ('ccomp', 34, 40), ('compound:nn', 43, 41), ('compound:nn', 43, 42), ('dep', 46, 43), ('case', 45, 44), ('nmod:prep', 46, 45), ('ccomp', 40, 46), ('punct', 2, 47), ('compound:nn', 50, 48), ('compound:nn', 50, 49), ('nmod:tmod', 60, 50), ('punct', 60, 51), ('nsubj', 54, 52), ('advmod', 54, 53), ('amod', 58, 54), ('mark', 54, 55), ('amod', 57, 56), ('compound:nn', 58, 57), ('nsubjpass', 60, 58), ('auxpass', 60, 59), ('conj', 2, 60), ('ccomp', 60, 61), ('ccomp', 61, 62), ('compound:nn', 65, 63), ('compound:nn', 65, 64), ('dobj', 62, 65), ('punct', 2, 66), ('det', 68, 67), ('nsubj', 70, 68), ('advmod', 70, 69), ('conj', 2, 70), ('nummod', 73, 71), ('mark:clf', 71, 72), ('nsubj', 74, 73), ('ccomp', 70, 74), ('nummod', 78, 75), ('mark:clf', 75, 76), ('compound:nn', 78, 77), ('dobj', 74, 78), ('punct', 2, 79), ('nsubj', 81, 80), ('conj', 2, 81), ('punct', 81, 82), ('amod', 84, 83), ('nmod:assmod', 88, 84), ('case', 84, 85), ('nummod', 88, 86), ('mark:clf', 86, 87), ('dep', 90, 88), ('name', 90, 89), ('dep', 97, 90), ('punct', 97, 91), ('name', 93, 92), ('dep', 97, 93), ('punct', 97, 94), ('cc', 97, 95), ('name', 97, 96), ('nsubj', 98, 97), ('ccomp', 81, 98), ('aux:asp', 98, 99), ('nmod', 102, 100), ('case', 100, 101), ('dobj', 98, 102), ('punct', 2, 103)]\n"
     ]
    }
   ],
   "source": [
    "with StanfordCoreNLP(r'C:\\Users\\19843\\Desktop\\natural_language_processing\\stanford-corenlp-full-2018-10-05', lang='zh') as nlp:\n",
    "    print('Constituency Parsing:\\n', nlp.parse(chitext))\n",
    "    print('\\nDependency Parsing:\\n', nlp.dependency_parse(chitext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyltp 中文依存句法分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学历\t造假\t风波\t一月\t后\t，\t翟\t天临\t与\t辛芷蕾\t牵手\t回家\t。\t\n",
      "武磊\t替补\t登场\t，\t梅西\t独\t中\t两\t元\t助\t巴萨\t2:0\t战胜\t西班牙人\t。\t\n",
      "漫\t威影业\t官方\t微博\t宣布\t《\t复仇者\t联盟\t4\t》\t正式\t定档\t4月\t24日\t在\t内地\t上映\t。\t\n",
      "\t3月\t29日\t下午\t，\t呼声\t极\t高\t的\t人工智能\t专业\t被\t列入\t新增\t审批\t本科\t专业\t名单\t，\t全国\t共有\t35\t所\t高校\t获\t首\t批\t建设\t资格\t。\n",
      "\tACM\t宣布\t，\t深度\t学习\t的\t三\t位\t创造者\tYoshua\tBengio\t，\tYann\tLeCun\t，\t以及\tGeoffrey\tHinton\t获得\t了\t2019年\t的\t图灵奖\t。\n",
      "n\tv\tn\tnt\tnd\twp\tnh\tv\tp\tnh\tv\tv\twp\tnh\tv\tv\twp\tnh\td\tv\tm\tq\tv\tnz\tm\tv\tn\twp\tv\tn\tn\tnz\tv\twp\tn\tn\tm\twp\ta\tv\tnt\tnt\tp\tnl\tv\twp\tv\tnt\tnt\tnt\twp\tn\td\ta\tu\tn\tn\tp\tv\tv\tv\tn\tn\tn\twp\tn\tv\tm\tq\tj\tv\tm\tq\tv\tn\twp\tws\tv\twp\tn\tv\tu\tm\tq\tn\tws\tws\twp\tws\tws\twp\tc\tws\tws\tv\tu\tnt\tu\tn\twp\n",
      "2:ATT\t3:ATT\t5:ATT\t5:ATT\t8:ADV\t5:WP\t8:SBV\t0:HED\t11:ADV\t9:POB\t8:COO\t11:COO\t8:WP\t15:SBV\t8:COO\t15:COO\t15:WP\t20:SBV\t20:ADV\t15:COO\t22:ATT\t23:SBV\t20:VOB\t23:VOB\t26:ADV\t23:VOB\t26:VOB\t8:WP\t30:ATT\t31:ATT\t32:ATT\t33:SBV\t8:COO\t37:WP\t36:ATT\t37:ATT\t45:SBV\t37:WP\t45:ADV\t45:SBV\t42:ATT\t45:ADV\t45:ADV\t43:POB\t33:VOB\t8:WP\t8:COO\t49:ATT\t50:ATT\t47:VOB\t8:WP\t54:SBV\t54:ADV\t57:ATT\t54:RAD\t57:ATT\t59:FOB\t59:ADV\t8:COO\t59:VOB\t62:ATT\t63:ATT\t64:ATT\t60:VOB\t8:WP\t67:SBV\t8:COO\t69:ATT\t70:ATT\t67:DBL\t67:VOB\t73:ATT\t75:ATT\t75:ATT\t71:VOB\t71:WP\t78:SBV\t71:COO\t78:WP\t81:ADV\t85:ATT\t81:RAD\t84:ATT\t85:ATT\t87:ATT\t87:ATT\t95:SBV\t87:WP\t90:ATT\t95:SBV\t90:WP\t94:LAD\t94:ATT\t95:SBV\t78:VOB\t95:RAD\t99:ATT\t97:RAD\t95:VOB\t8:WP\n"
     ]
    }
   ],
   "source": [
    "# 分词\n",
    "from pyltp import Segmentor\n",
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load(r'D:\\browser_download\\ltp_data_v3.4.0\\cws.model')  # 加载模型\n",
    "words = segmentor.segment(chitext)  # 分词\n",
    "print('\\t'.join(words))\n",
    "segmentor.release()  # 释放模型\n",
    "words_list = list(words)\n",
    "\n",
    "#词性标注\n",
    "from pyltp import Postagger\n",
    "postagger = Postagger() # 初始化实例\n",
    "postagger.load(r'D:\\browser_download\\ltp_data_v3.4.0\\pos.model')  # 加载模型\n",
    "postags = postagger.postag(words)  # 词性标注\n",
    "print('\\t'.join(postags))\n",
    "postagger.release()  # 释放模型\n",
    "\n",
    "# 依存句法分析\n",
    "from pyltp import Parser\n",
    "parser = Parser() # 初始化实例\n",
    "parser.load(r'D:\\browser_download\\ltp_data_v3.4.0\\parser.model')  # 加载模型\n",
    "arcs = parser.parse(words, postags)  # 句法分析\n",
    "print(\"\\t\".join(\"%d:%s\" % (arc.head, arc.relation) for arc in arcs))\n",
    "parser.release()  # 释放模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
