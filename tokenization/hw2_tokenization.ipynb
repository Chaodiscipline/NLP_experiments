{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment 2 利用分词工具进行中英文文档分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "with open(\"C:\\\\Users\\\\19843\\\\Desktop\\\\natural_language_processing\\\\Experiment2\\\\Chinese.txt\", 'rb') as f:\n",
    "    Chinese_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieba三种分词模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全模式:\n",
      " 央视/ 315/ 晚会/ 曝光/ 湖北/ 湖北省/ 知名/ 的/ 神丹/ 牌/ / / 莲/ 田/ 牌/ / / 土鸡/ 鸡蛋/ / / 实为/ 普通/ 鸡蛋/ 冒充/ / / 同时/ 在/ 商标/ 标上/ 玩/ 猫腻/ / / 分别/ 注册/ / / 鲜/ 土/ / / / 注册/ / / 好/ 土/ / / 商标/ / / 让/ 消费/ 消费者/ 误以为/ 以为/ 是/ / / 土鸡/ 鸡蛋/ / / 3/ 月/ 15/ 日/ 晚间/ / / 新/ 京报/ 记者/ 就此/ 此事/ 致电/ 湖北/ 神丹/ 健康/ 食品/ 有限/ 有限公司/ 公司/ 方面/ / / 其/ 工作/ 工作人员/ 作人/ 人员/ 表示/ 不知/ 不知情/ 知情/ / / 需要/ 了解/ 清楚/ 情况/ / / 截至/ 发稿/ 暂/ 未取/ 取得/ 最新/ 回应/ / / 新/ 京报/ 记者/ 还/ 查询/ 发现/ / / 湖北/ 神丹/ 健康/ 食品/ 有限/ 有限公司/ 公司/ 为/ 农业/ 农业产业/ 产业/ 产业化/ 国家/ 重点/ 龙头/ 龙头企业/ 企业/ / / 高新/ 高新技术/ 技术/ 企业/ / / 此前/ 曾/ 因涉嫌/ 涉嫌/ 虚假/ 宣传/ / / 中国/ 最大/ 的/ 蛋品/ 企业/ / / 而/ 被/ 罚/ 6/ 万元/ / \n",
      "\n",
      "精确模式: \n",
      "央视/ 315/ 晚会/ 曝光/ 湖北省/ 知名/ 的/ 神丹/ 牌/ 、/ 莲田牌/ “/ 土/ 鸡蛋/ ”/ 实为/ 普通/ 鸡蛋/ 冒充/ ，/ 同时/ 在/ 商标/ 上/ 玩/ 猫腻/ ，/ 分别/ 注册/ “/ 鲜土/ ”/ 、/ 注册/ “/ 好土/ ”/ 商标/ ，/ 让/ 消费者/ 误以为/ 是/ “/ 土/ 鸡蛋/ ”/ 。/ 3/ 月/ 15/ 日/ 晚间/ ，/ 新/ 京报/ 记者/ 就/ 此事/ 致电/ 湖北/ 神丹/ 健康/ 食品/ 有限公司/ 方面/ ，/ 其/ 工作人员/ 表示/ 不知情/ ，/ 需要/ 了解/ 清楚/ 情况/ ，/ 截至/ 发稿/ 暂未/ 取得/ 最新/ 回应/ 。/ 新/ 京报/ 记者/ 还/ 查询/ 发现/ ，/ 湖北/ 神丹/ 健康/ 食品/ 有限公司/ 为/ 农业/ 产业化/ 国家/ 重点/ 龙头企业/ 、/ 高新技术/ 企业/ ，/ 此前/ 曾/ 因涉嫌/ 虚假/ 宣传/ “/ 中国/ 最大/ 的/ 蛋品/ 企业/ ”/ 而/ 被/ 罚/ 6/ 万元/ 。\n",
      "\n",
      "搜索引擎模式:\n",
      " 央视, 315, 晚会, 曝光, 湖北, 湖北省, 知名, 的, 神丹, 牌, 、, 莲田牌, “, 土, 鸡蛋, ”, 实为, 普通, 鸡蛋, 冒充, ，, 同时, 在, 商标, 上, 玩, 猫腻, ，, 分别, 注册, “, 鲜土, ”, 、, 注册, “, 好土, ”, 商标, ，, 让, 消费, 消费者, 以为, 误以为, 是, “, 土, 鸡蛋, ”, 。, 3, 月, 15, 日, 晚间, ，, 新, 京报, 记者, 就, 此事, 致电, 湖北, 神丹, 健康, 食品, 有限, 公司, 有限公司, 方面, ，, 其, 工作, 作人, 人员, 工作人员, 表示, 不知, 知情, 不知情, ，, 需要, 了解, 清楚, 情况, ，, 截至, 发稿, 暂未, 取得, 最新, 回应, 。, 新, 京报, 记者, 还, 查询, 发现, ，, 湖北, 神丹, 健康, 食品, 有限, 公司, 有限公司, 为, 农业, 产业, 产业化, 国家, 重点, 龙头, 企业, 龙头企业, 、, 高新, 技术, 高新技术, 企业, ，, 此前, 曾, 涉嫌, 因涉嫌, 虚假, 宣传, “, 中国, 最大, 的, 蛋品, 企业, ”, 而, 被, 罚, 6, 万元, 。\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(Chinese_text, cut_all=True)  # 全模式\n",
    "print(\"全模式:\\n \" + \"/ \".join(seg_list))  \n",
    "\n",
    "seg_list = jieba.cut(Chinese_text)\n",
    "print(\"\\n精确模式: \\n\" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "seg_list = jieba.cut_for_search(Chinese_text)  # 搜索引擎模式\n",
    "print(\"\\n搜索引擎模式:\\n\",\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieba 自定义词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "精确模式: \n",
      "央视/ 315/ 晚会/ 曝光/ 湖北省/ 知名/ 的/ 神丹牌/ 、/ 莲田牌/ “/ 土鸡蛋/ ”/ 实为/ 普通/ 鸡蛋/ 冒充/ ，/ 同时/ 在/ 商标/ 上/ 玩/ 猫腻/ ，/ 分别/ 注册/ “/ 鲜/ 土/ ”/ 、/ 注册/ “/ 好/ 土/ ”/ 商标/ ，/ 让/ 消费者/ 误以为/ 是/ “/ 土鸡蛋/ ”/ 。/ 3/ 月/ 15/ 日/ 晚间/ ，/ 新京报/ 记者/ 就/ 此事/ 致电/ 湖北/ 神丹/ 健康/ 食品/ 有限公司/ 方面/ ，/ 其/ 工作人员/ 表示/ 不知情/ ，/ 需要/ 了解/ 清楚/ 情况/ ，/ 截至/ 发稿/ 暂/ 未/ 取得/ 最新/ 回应/ 。/ 新京报/ 记者/ 还/ 查询/ 发现/ ，/ 湖北/ 神丹/ 健康/ 食品/ 有限公司/ 为/ 农业/ 产业化/ 国家/ 重点/ 龙头企业/ 、/ 高新技术/ 企业/ ，/ 此前/ 曾/ 因涉嫌/ 虚假/ 宣传/ “/ 中国/ 最大/ 的/ 蛋品/ 企业/ ”/ 而/ 被/ 罚/ 6/ 万元/ 。\n",
      "\n",
      "精确模式: \n",
      "央视/ 315/ 晚会/ 曝光/ 湖北省/ 知名/ 的/ 神丹牌/ 、/ 莲田牌/ “/ 土鸡蛋/ ”/ 实为/ 普通/ 鸡蛋/ 冒充/ ，/ 同时/ 在/ 商标/ 上/ 玩/ 猫腻/ ，/ 分别/ 注册/ “/ 鲜/ 土/ ”/ 、/ 注册/ “/ 好/ 土/ ”/ 商标/ ，/ 让/ 消费者/ 误以为/ 是/ “/ 土鸡蛋/ ”/ 。/ 3/ 月/ 15/ 日/ 晚间/ ，/ 新京报/ 记者/ 就/ 此事/ 致电/ 湖北/ 神丹/ 健康/ 食品/ 有限公司/ 方面/ ，/ 其/ 工作人员/ 表示/ 不知情/ ，/ 需要/ 了解/ 清楚/ 情况/ ，/ 截至/ 发稿/ 暂/ 未/ 取得/ 最新/ 回应/ 。/ 新京报/ 记者/ 还/ 查询/ 发现/ ，/ 湖北/ 神丹/ 健康/ 食品/ 有限公司/ 为/ 农业/ 产业化/ 国家/ 重点/ 龙头企业/ 、/ 高新技术/ 企业/ ，/ 此前/ 曾/ 因涉嫌/ 虚假/ 宣传/ “/ 中国/ 最大/ 的/ 蛋品/ 企业/ ”/ 而/ 被/ 罚/ 6/ 万元/ 。\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict(\"new_dict.txt\")\n",
    "\n",
    "seg_list = jieba.cut(Chinese_text, HMM=False)\n",
    "print(\"\\n精确模式: \\n\" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "jieba.add_word('莲田牌')\n",
    "seg_list = jieba.cut(Chinese_text, HMM=False)\n",
    "print(\"\\n精确模式: \\n\" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "#jieba.suggest_freq('土鸡蛋'，True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# snownlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snownlp import SnowNLP\n",
    "\n",
    "with open(\"C:\\\\Users\\\\19843\\\\Desktop\\\\natural_language_processing\\\\Experiment2\\\\Chinese.txt\", 'r') as f:\n",
    "    Chinese_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\n",
      " ['央视', '315', '晚会', '曝光', '湖北省', '知名', '的', '神丹', '牌', '、', '莲', '田', '牌', '“', '土', '鸡蛋', '”', '实', '为', '普通', '鸡蛋', '冒充', '，', '同时', '在', '商标', '上', '玩猫', '腻', '，', '分别', '注册', '“', '鲜', '土', '”、', '注册', '“', '好', '土', '”', '商标', '，', '让', '消费者', '误', '以为', '是', '“', '土', '鸡蛋', '”。3', '月', '15', '日', '晚间', '，', '新京', '报', '记者', '就', '此事', '致电', '湖北', '神', '丹', '健康', '食品', '有限公司', '方面', '，', '其', '工作', '人员', '表示', '不', '知情', '，', '需要', '了解', '清楚', '情况', '，', '截至', '发稿', '暂', '未', '取得', '最新', '回应', '。', '新京', '报', '记者', '还', '查询', '发现', '，', '湖北', '神', '丹', '健康', '食品', '有限公司', '为', '农业', '产业化', '国家', '重点', '龙头', '企业', '、', '高新技术', '企业', '，', '此前', '曾', '因', '涉嫌', '虚假', '宣传', '“', '中国', '最', '大', '的', '蛋品', '企业', '”', '而', '被', '罚', '6', '万', '元', '。']\n",
      "\n",
      " <zip object at 0x00000239CC4C6788>\n",
      "\n",
      " ['土', '企业', '商标', '牌']\n",
      "\n",
      " ['新京报记者就此事致电湖北神丹健康食品有限公司方面', '让消费者误以为是“土鸡蛋”', '湖北神丹健康食品有限公司为农业产业化国家重点龙头企业、高新技术企业', '分别注册“鲜土”、注册“好土”商标']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(type(Chinese_text))\n",
    "    \n",
    "s = SnowNLP(Chinese_text)\n",
    "print(\"\\n\",s.words)\n",
    "print(\"\\n\",s.tags)\n",
    "print(\"\\n\",s.keywords(4))\n",
    "print(\"\\n\",s.summary(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thulac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded succeed\n",
      "央视_v 315_m 晚会_n 曝光_v 湖北省_ns 知名_a 的_u 神丹牌_nz 、_w 莲田牌_nz “_w 土_a 鸡蛋_n ”_w 实_a 为_v 普通_a 鸡蛋_n 冒充_v ，_w 同时_c 在_p 商标_n 上_f 玩_v 猫腻_n ，_w 分别_d 注册_v “_w 鲜土_n ”_w 、_w 注册_v “_w 好_a 土_n ”_w 商标_n ，_w 让_v 消费者_n 误_d 以为_v 是_v “_w 土鸡蛋_n ”_w 。_w 3月_t 15日_t 晚间_t ，_w 新京报_nz 记者_n 就_p 此事_r 致电_v 湖北_ns 神丹_nz 健康_a 食品_n 有限公司_n 方面_n ，_w 其_r 工作_v 人员_n 表示_v 不_d 知情_v ，_w 需要_v 了_u 解_v 清楚_a 情况_n ，_w 截至_v 发稿_v 暂_d 未_d 取得_v 最新_a 回应_v 。_w 新_a 京报_n 记者_n 还_d 查询_v 发现_v ，_w 湖北_ns 神丹_nz 健康_a 食品_n 有限公司_n 为_p 农业_n 产业化_v 国_m 家_q 重点_n 龙头_n 企业_n 、_w 高新技术_n 企业_n ，_w 此前_t 曾_d 因_p 涉嫌_v 虚假_a 宣传_v “_w 中国_ns 最_d 大_a 的_u 蛋品_n 企业_n ”_w 而_c 被_p 罚_v 6万_m 元_q 。_w\n",
      "Model loaded succeed\n",
      "<thulac.thulac object at 0x00000256D9D8D898>\n"
     ]
    }
   ],
   "source": [
    "import thulac\n",
    "\n",
    "\n",
    "thu1 = thulac.thulac()  #默认模式\n",
    "text = thu1.cut(Chinese_text, text=True)  #进行一句话分词\n",
    "print(text)\n",
    "\n",
    "thu2 = thulac.thulac(seg_only=True)  #只进行分词，不进行词性标注\n",
    "print(thu2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pynlpir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "part of speech not recognized: 'gnbj'\n",
      "part of speech not recognized: 'gnbj'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('央', 'verb'), ('视', 'verb'), ('315', 'numeral'), ('晚会', 'noun'), ('曝光', 'verb'), ('湖北省', 'noun'), ('知名', 'adjective'), ('的', 'particle'), ('神', 'noun'), ('丹', 'distinguishing word'), ('牌', 'noun'), ('、', 'punctuation mark'), ('莲', 'noun'), ('田', 'noun'), ('牌', 'noun'), ('“', 'punctuation mark'), ('土', 'noun'), ('鸡蛋', 'noun'), ('”', 'punctuation mark'), ('实', 'adjective'), ('为', 'verb'), ('普通', 'adjective'), ('鸡蛋', 'noun'), ('冒充', 'verb'), ('，', 'punctuation mark'), ('同时', 'conjunction'), ('在', 'preposition'), ('商标', 'noun'), ('上', 'noun of locality'), ('玩', 'verb'), ('猫腻', 'noun'), ('，', 'punctuation mark'), ('分别', 'adverb'), ('注册', 'verb'), ('“', 'punctuation mark'), ('鲜', 'adjective'), ('土', 'noun'), ('”', 'punctuation mark'), ('、', 'punctuation mark'), ('注册', 'verb'), ('“', 'punctuation mark'), ('好', 'adjective'), ('土', 'noun'), ('”', 'punctuation mark'), ('商标', 'noun'), ('，', 'punctuation mark'), ('让', 'verb'), ('消费者', 'noun'), ('误', 'adverb'), ('以为', 'verb'), ('是', 'verb'), ('“', 'punctuation mark'), ('土', 'noun'), ('鸡蛋', 'noun'), ('”', 'punctuation mark'), ('。', 'punctuation mark'), ('3月', 'time word'), ('15日', 'time word'), ('晚间', 'time word'), ('，', 'punctuation mark'), ('新京报', None), ('记者', 'noun'), ('就', 'adverb'), ('此事', 'pronoun'), ('致电', 'verb'), ('湖北', 'noun'), ('神', 'noun'), ('丹', 'distinguishing word'), ('健康', 'adjective'), ('食品', 'noun'), ('有限公司', 'noun'), ('方面', 'noun'), ('，', 'punctuation mark'), ('其', 'pronoun'), ('工作', 'verb'), ('人员', 'noun'), ('表示', 'verb'), ('不', 'adverb'), ('知', 'verb'), ('情', 'noun'), ('，', 'punctuation mark'), ('需要', 'verb'), ('了解', 'verb'), ('清楚', 'adjective'), ('情况', 'noun'), ('，', 'punctuation mark'), ('截至', 'verb'), ('发稿', 'verb'), ('暂', 'adverb'), ('未', 'adverb'), ('取得', 'verb'), ('最新', 'adjective'), ('回应', 'verb'), ('。', 'punctuation mark'), ('新京报', None), ('记者', 'noun'), ('还', 'adverb'), ('查询', 'verb'), ('发现', 'verb'), ('，', 'punctuation mark'), ('湖北', 'noun'), ('神', 'noun'), ('丹', 'distinguishing word'), ('健康', 'adjective'), ('食品', 'noun'), ('有限公司', 'noun'), ('为', 'preposition'), ('农业', 'noun'), ('产业化', 'verb'), ('国家', 'noun'), ('重点', 'noun'), ('龙头', 'noun'), ('企业', 'noun'), ('、', 'punctuation mark'), ('高新技术', 'noun'), ('企业', 'noun'), ('，', 'punctuation mark'), ('此前', 'time word'), ('曾', 'adverb'), ('因', 'preposition'), ('涉嫌', 'verb'), ('虚假', 'adjective'), ('宣传', 'verb'), ('“', 'punctuation mark'), ('中国', 'noun'), ('最', 'adverb'), ('大', 'adjective'), ('的', 'particle'), ('蛋品', 'noun'), ('企业', 'noun'), ('”', 'punctuation mark'), ('而', 'conjunction'), ('被', 'preposition'), ('罚', 'verb'), ('6万', 'numeral'), ('元', 'classifier'), ('。', 'punctuation mark')]\n"
     ]
    }
   ],
   "source": [
    "import pynlpir\n",
    "\n",
    "pynlpir.open()\n",
    "# s = 'NLPIR分词系统前身为2000年发布的ICTCLAS词法分析系统，从2009年开始，为了和以前工作进行大的区隔，并推广NLPIR自然语言处理与信息检索共享平台，调整命名为NLPIR分词系统。'\n",
    "# pynlpir.segment(s)\n",
    "result = pynlpir.segment(Chinese_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['央视', '315', '晚会', '曝光', '湖北省', '知名', '的', '神丹', '牌', '、', '莲', '田', '牌', '“', '土', '鸡蛋', '”', '实为', '普通', '鸡蛋', '冒充', '，', '同时', '在', '商标', '上', '玩', '猫腻', '，', '分别', '注册', '“', '鲜土', '”', '、', '注册', '“', '好', '土', '”', '商标', '，', '让', '消费者', '误以为', '是', '“', '土', '鸡蛋', '”', '。', '3月', '15日', '晚间', '，', '新京报', '记者', '就此事', '致电', '湖北', '神丹', '健康', '食品', '有限', '公司', '方面', '，', '其', '工作', '人员', '表示', '不知情', '，', '需要', '了解', '清楚', '情况', '，', '截至', '发稿', '暂', '未', '取得', '最新', '回应', '。', '新京报', '记者', '还', '查询', '发现', '，', '湖北', '神丹', '健康', '食品', '有限', '公司', '为', '农业', '产业化', '国家', '重点', '龙头', '企业', '、', '高', '新', '技术', '企业', '，', '此前', '曾', '因', '涉嫌', '虚假', '宣传', '“', '中国', '最', '大', '的', '蛋品', '企业', '”', '而', '被', '罚', '6万', '元', '。']\n",
      "[('央视', 'NR'), ('315', 'CD'), ('晚会', 'NN'), ('曝光', 'VV'), ('湖北省', 'NR'), ('知名', 'VA'), ('的', 'DEC'), ('神丹', 'NR'), ('牌', 'NN'), ('、', 'PU'), ('莲', 'NR'), ('田', 'NN'), ('牌', 'NN'), ('“', 'PU'), ('土', 'JJ'), ('鸡蛋', 'NN'), ('”', 'PU'), ('实为', 'AD'), ('普通', 'JJ'), ('鸡蛋', 'NN'), ('冒充', 'VV'), ('，', 'PU'), ('同时', 'AD'), ('在', 'P'), ('商标', 'NN'), ('上', 'LC'), ('玩', 'VV'), ('猫腻', 'NN'), ('，', 'PU'), ('分别', 'AD'), ('注册', 'VV'), ('“', 'PU'), ('鲜土', 'NN'), ('”', 'PU'), ('、', 'PU'), ('注册', 'NN'), ('“', 'PU'), ('好', 'JJ'), ('土', 'NN'), ('”', 'PU'), ('商标', 'NN'), ('，', 'PU'), ('让', 'VV'), ('消费者', 'NN'), ('误以为', 'NR'), ('是', 'VC'), ('“', 'PU'), ('土', 'JJ'), ('鸡蛋', 'NN'), ('”', 'PU'), ('。', 'PU'), ('3月', 'NT'), ('15日', 'NT'), ('晚间', 'NT'), ('，', 'PU'), ('新京报', 'NR'), ('记者', 'NN'), ('就此事', 'NR'), ('致电', 'VV'), ('湖北', 'NR'), ('神丹', 'NR'), ('健康', 'JJ'), ('食品', 'NN'), ('有限', 'JJ'), ('公司', 'NN'), ('方面', 'NN'), ('，', 'PU'), ('其', 'PN'), ('工作', 'NN'), ('人员', 'NN'), ('表示', 'VV'), ('不知情', 'NN'), ('，', 'PU'), ('需要', 'VV'), ('了解', 'VV'), ('清楚', 'VA'), ('情况', 'NN'), ('，', 'PU'), ('截至', 'P'), ('发稿', 'VV'), ('暂', 'AD'), ('未', 'AD'), ('取得', 'VV'), ('最新', 'JJ'), ('回应', 'NN'), ('。', 'PU'), ('新京报', 'NR'), ('记者', 'NN'), ('还', 'AD'), ('查询', 'VV'), ('发现', 'VV'), ('，', 'PU'), ('湖北', 'NR'), ('神丹', 'NR'), ('健康', 'JJ'), ('食品', 'NN'), ('有限', 'JJ'), ('公司', 'NN'), ('为', 'VV'), ('农业', 'NN'), ('产业化', 'NN'), ('国家', 'NN'), ('重点', 'NN'), ('龙头', 'NN'), ('企业', 'NN'), ('、', 'PU'), ('高', 'JJ'), ('新', 'JJ'), ('技术', 'NN'), ('企业', 'NN'), ('，', 'PU'), ('此前', 'AD'), ('曾', 'AD'), ('因', 'P'), ('涉嫌', 'VV'), ('虚假', 'JJ'), ('宣传', 'NN'), ('“', 'PU'), ('中国', 'NR'), ('最', 'AD'), ('大', 'VA'), ('的', 'DEC'), ('蛋品', 'NN'), ('企业', 'NN'), ('”', 'PU'), ('而', 'MSP'), ('被', 'SB'), ('罚', 'VV'), ('6万', 'CD'), ('元', 'M'), ('。', 'PU')]\n",
      "[('央视', 'ORGANIZATION'), ('315', 'ORGANIZATION'), ('晚会', 'ORGANIZATION'), ('曝光', 'O'), ('湖北省', 'STATE_OR_PROVINCE'), ('知名', 'O'), ('的', 'O'), ('神丹', 'O'), ('牌', 'O'), ('、', 'O'), ('莲', 'O'), ('田', 'O'), ('牌', 'O'), ('“', 'O'), ('土', 'O'), ('鸡蛋', 'O'), ('”', 'O'), ('实为', 'O'), ('普通', 'O'), ('鸡蛋', 'O'), ('冒充', 'O'), ('，', 'O'), ('同时', 'O'), ('在', 'O'), ('商标', 'O'), ('上', 'O'), ('玩', 'O'), ('猫腻', 'O'), ('，', 'O'), ('分别', 'O'), ('注册', 'O'), ('“', 'O'), ('鲜土', 'O'), ('”', 'O'), ('、', 'O'), ('注册', 'O'), ('“', 'O'), ('好', 'O'), ('土', 'O'), ('”', 'O'), ('商标', 'O'), ('，', 'O'), ('让', 'O'), ('消费者', 'O'), ('误以为', 'O'), ('是', 'O'), ('“', 'O'), ('土', 'O'), ('鸡蛋', 'O'), ('”', 'O'), ('。', 'O'), ('3月', 'DATE'), ('15日', 'DATE'), ('晚间', 'TIME'), ('，', 'O'), ('新京报', 'MISC'), ('记者', 'TITLE'), ('就此事', 'PERSON'), ('致电', 'O'), ('湖北', 'ORGANIZATION'), ('神丹', 'ORGANIZATION'), ('健康', 'ORGANIZATION'), ('食品', 'ORGANIZATION'), ('有限', 'ORGANIZATION'), ('公司', 'ORGANIZATION'), ('方面', 'O'), ('，', 'O'), ('其', 'O'), ('工作', 'O'), ('人员', 'O'), ('表示', 'O'), ('不知情', 'O'), ('，', 'O'), ('需要', 'O'), ('了解', 'O'), ('清楚', 'O'), ('情况', 'O'), ('，', 'O'), ('截至', 'O'), ('发稿', 'O'), ('暂', 'O'), ('未', 'O'), ('取得', 'O'), ('最新', 'O'), ('回应', 'O'), ('。', 'O'), ('新京报', 'MISC'), ('记者', 'TITLE'), ('还', 'O'), ('查询', 'O'), ('发现', 'O'), ('，', 'O'), ('湖北', 'ORGANIZATION'), ('神丹', 'ORGANIZATION'), ('健康', 'ORGANIZATION'), ('食品', 'ORGANIZATION'), ('有限', 'ORGANIZATION'), ('公司', 'ORGANIZATION'), ('为', 'O'), ('农业', 'O'), ('产业化', 'O'), ('国家', 'O'), ('重点', 'O'), ('龙头', 'O'), ('企业', 'O'), ('、', 'O'), ('高', 'O'), ('新', 'O'), ('技术', 'O'), ('企业', 'O'), ('，', 'O'), ('此前', 'O'), ('曾', 'O'), ('因', 'O'), ('涉嫌', 'O'), ('虚假', 'O'), ('宣传', 'O'), ('“', 'O'), ('中国', 'COUNTRY'), ('最', 'O'), ('大', 'O'), ('的', 'O'), ('蛋品', 'O'), ('企业', 'O'), ('”', 'O'), ('而', 'O'), ('被', 'O'), ('罚', 'O'), ('6万', 'MONEY'), ('元', 'MONEY'), ('。', 'O')]\n",
      "(ROOT\n",
      "  (IP\n",
      "    (IP\n",
      "      (NP\n",
      "        (NP (NR 央视))\n",
      "        (QP (CD 315))\n",
      "        (NP (NN 晚会)))\n",
      "      (VP\n",
      "        (VP (VV 曝光)\n",
      "          (IP\n",
      "            (NP\n",
      "              (NP (NR 湖北省))\n",
      "              (CP\n",
      "                (IP\n",
      "                  (VP (VA 知名)))\n",
      "                (DEC 的))\n",
      "              (NP (NR 神丹) (NN 牌))\n",
      "              (PU 、)\n",
      "              (NP\n",
      "                (NP\n",
      "                  (NP (NR 莲) (NN 田))\n",
      "                  (NP (NN 牌)))\n",
      "                (NP (PU “)\n",
      "                  (ADJP (JJ 土))\n",
      "                  (NP (NN 鸡蛋))\n",
      "                  (PU ”))))\n",
      "            (ADVP (AD 实为))\n",
      "            (NP\n",
      "              (ADJP (JJ 普通))\n",
      "              (NP (NN 鸡蛋)))\n",
      "            (VP (VV 冒充))))\n",
      "        (PU ，)\n",
      "        (VP\n",
      "          (ADVP (AD 同时))\n",
      "          (PP (P 在)\n",
      "            (LCP\n",
      "              (NP (NN 商标))\n",
      "              (LC 上)))\n",
      "          (VP (VV 玩)\n",
      "            (NP (NN 猫腻))))))\n",
      "    (PU ，)\n",
      "    (IP\n",
      "      (VP\n",
      "        (ADVP (AD 分别))\n",
      "        (VP (VV 注册)\n",
      "          (NP (PU “) (NN 鲜土) (PU ”)))))\n",
      "    (PU 、)\n",
      "    (IP\n",
      "      (NP\n",
      "        (NP (NN 注册))\n",
      "        (NP (PU “)\n",
      "          (ADJP (JJ 好))\n",
      "          (NP (NN 土))\n",
      "          (PU ”))\n",
      "        (NP (NN 商标)))\n",
      "      (PU ，)\n",
      "      (VP (VV 让)\n",
      "        (NP\n",
      "          (NP (NN 消费者))\n",
      "          (NP (NR 误以为)))\n",
      "        (IP\n",
      "          (VP (VC 是)\n",
      "            (NP (PU “)\n",
      "              (ADJP (JJ 土))\n",
      "              (NP (NN 鸡蛋))\n",
      "              (PU ”))))))\n",
      "    (PU 。)\n",
      "    (IP\n",
      "      (NP (NT 3月) (NT 15日) (NT 晚间))\n",
      "      (PU ，)\n",
      "      (NP\n",
      "        (NP\n",
      "          (NP (NR 新京报))\n",
      "          (NP (NN 记者)))\n",
      "        (NP (NR 就此事)))\n",
      "      (IP\n",
      "        (VP\n",
      "          (VP (VV 致电)\n",
      "            (NP\n",
      "              (NP\n",
      "                (NP (NR 湖北) (NR 神丹))\n",
      "                (ADJP (JJ 健康))\n",
      "                (NP (NN 食品))\n",
      "                (ADJP (JJ 有限))\n",
      "                (NP (NN 公司)))\n",
      "              (NP (NN 方面))))\n",
      "          (PU ，)\n",
      "          (PRN\n",
      "            (IP\n",
      "              (NP\n",
      "                (NP (PN 其))\n",
      "                (NP (NN 工作) (NN 人员)))\n",
      "              (VP\n",
      "                (VP (VV 表示)\n",
      "                  (NP (NN 不知情)))\n",
      "                (PU ，)\n",
      "                (VP (VV 需要)\n",
      "                  (VP\n",
      "                    (VRD (VV 了解) (VA 清楚))\n",
      "                    (NP (NN 情况)))))))\n",
      "          (PU ，)\n",
      "          (PP (P 截至)\n",
      "            (IP\n",
      "              (VP (VV 发稿)\n",
      "                (IP\n",
      "                  (VP\n",
      "                    (ADVP (AD 暂))\n",
      "                    (ADVP (AD 未))\n",
      "                    (VP (VV 取得)\n",
      "                      (NP\n",
      "                        (ADJP (JJ 最新))\n",
      "                        (NP (NN 回应))))))))))\n",
      "        (PU 。)\n",
      "        (IP\n",
      "          (NP\n",
      "            (NP (NR 新京报))\n",
      "            (NP (NN 记者)))\n",
      "          (VP\n",
      "            (ADVP (AD 还))\n",
      "            (VP (VV 查询)\n",
      "              (IP\n",
      "                (VP (VV 发现) (PU ，)\n",
      "                  (IP\n",
      "                    (IP\n",
      "                      (NP\n",
      "                        (NP (NR 湖北) (NR 神丹))\n",
      "                        (ADJP (JJ 健康))\n",
      "                        (NP (NN 食品))\n",
      "                        (ADJP (JJ 有限))\n",
      "                        (NP (NN 公司)))\n",
      "                      (VP (VV 为)\n",
      "                        (NP (NN 农业) (NN 产业化) (NN 国家) (NN 重点) (NN 龙头) (NN 企业) (PU 、)\n",
      "                          (ADJP (JJ 高) (JJ 新))\n",
      "                          (NP (NN 技术) (NN 企业)))))\n",
      "                    (PU ，)\n",
      "                    (PP\n",
      "                      (ADVP (AD 此前))\n",
      "                      (ADVP (AD 曾))\n",
      "                      (PP (P 因)\n",
      "                        (IP\n",
      "                          (VP (VV 涉嫌)\n",
      "                            (IP\n",
      "                              (NP\n",
      "                                (ADJP (JJ 虚假))\n",
      "                                (NP (NN 宣传)))\n",
      "                              (PU “)\n",
      "                              (NP\n",
      "                                (CP\n",
      "                                  (IP\n",
      "                                    (NP (NR 中国))\n",
      "                                    (VP\n",
      "                                      (ADVP (AD 最))\n",
      "                                      (VP (VA 大))))\n",
      "                                  (DEC 的))\n",
      "                                (NP (NN 蛋品) (NN 企业)))\n",
      "                              (PU ”)\n",
      "                              (VP (MSP 而)\n",
      "                                (VP (SB 被)\n",
      "                                  (VP (VV 罚)\n",
      "                                    (QP (CD 6万)\n",
      "                                      (CLP (M 元)))))))))))))))))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    (PU 。)))\n",
      "[('ROOT', 0, 4), ('nmod', 3, 1), ('dep', 3, 2), ('nsubj', 4, 3), ('nmod', 13, 5), ('amod', 13, 6), ('mark', 6, 7), ('nmod:assmod', 9, 8), ('conj', 13, 9), ('punct', 13, 10), ('compound:nn', 12, 11), ('nmod:assmod', 13, 12), ('nsubj', 21, 13), ('punct', 16, 14), ('amod', 16, 15), ('parataxis:prnmod', 13, 16), ('punct', 16, 17), ('advmod', 21, 18), ('amod', 20, 19), ('nsubj', 21, 20), ('ccomp', 4, 21), ('punct', 4, 22), ('advmod', 27, 23), ('case', 25, 24), ('nmod:prep', 27, 25), ('case', 25, 26), ('conj', 4, 27), ('dobj', 27, 28), ('punct', 4, 29), ('advmod', 31, 30), ('conj', 4, 31), ('punct', 33, 32), ('conj', 36, 33), ('punct', 33, 34), ('punct', 36, 35), ('compound:nn', 41, 36), ('punct', 39, 37), ('amod', 39, 38), ('compound:nn', 41, 39), ('punct', 39, 40), ('dobj', 31, 41), ('punct', 4, 42), ('conj', 4, 43), ('dobj', 43, 44), ('nsubj', 49, 45), ('cop', 49, 46), ('punct', 49, 47), ('amod', 49, 48), ('ccomp', 43, 49), ('punct', 4, 50), ('punct', 4, 51), ('compound:nn', 54, 52), ('compound:nn', 54, 53), ('nmod:tmod', 59, 54), ('punct', 59, 55), ('nmod:assmod', 57, 56), ('appos', 58, 57), ('nsubj', 59, 58), ('conj', 4, 59), ('name', 61, 60), ('compound:nn', 65, 61), ('amod', 63, 62), ('compound:nn', 65, 63), ('amod', 65, 64), ('compound:nn', 66, 65), ('dobj', 59, 66), ('punct', 4, 67), ('compound:nn', 70, 68), ('compound:nn', 70, 69), ('nsubj', 71, 70), ('conj', 4, 71), ('dobj', 71, 72), ('punct', 71, 73), ('xcomp', 75, 74), ('conj', 71, 75), ('advmod:rcomp', 75, 76), ('dobj', 75, 77), ('punct', 75, 78), ('case', 80, 79), ('nmod:prep', 83, 80), ('advmod', 83, 81), ('advmod', 83, 82), ('conj', 75, 83), ('amod', 85, 84), ('dobj', 83, 85), ('punct', 4, 86), ('nmod:assmod', 88, 87), ('nsubj', 91, 88), ('advmod', 91, 89), ('compound:vc', 91, 90), ('conj', 4, 91), ('punct', 91, 92), ('name', 94, 93), ('nmod:assmod', 98, 94), ('amod', 96, 95), ('compound:nn', 98, 96), ('amod', 98, 97), ('nsubj', 99, 98), ('ccomp', 91, 99), ('compound:nn', 105, 100), ('compound:nn', 105, 101), ('compound:nn', 105, 102), ('compound:nn', 105, 103), ('compound:nn', 105, 104), ('conj', 110, 105), ('punct', 110, 106), ('amod', 109, 107), ('amod', 109, 108), ('compound:nn', 110, 109), ('dobj', 99, 110), ('punct', 99, 111), ('advmod', 128, 112), ('advmod', 128, 113), ('case', 115, 114), ('nmod:prep', 128, 115), ('amod', 117, 116), ('dobj', 115, 117), ('punct', 124, 118), ('dep', 121, 119), ('advmod', 121, 120), ('amod', 124, 121), ('mark', 121, 122), ('compound:nn', 124, 123), ('dobj', 115, 124), ('punct', 124, 125), ('aux:prtmod', 128, 126), ('auxpass', 128, 127), ('conj', 99, 128), ('nmod:range', 128, 129), ('mark:clf', 129, 130), ('punct', 4, 131)]\n"
     ]
    }
   ],
   "source": [
    "# Other human languages support, e.g. Chinese\n",
    "\n",
    "with StanfordCoreNLP(r'C:\\Users\\19843\\Desktop\\natural_language_processing\\stanford-corenlp-full-2018-10-05', lang='zh') as nlp:\n",
    "    print(nlp.word_tokenize(Chinese_text))\n",
    "    print(nlp.pos_tag(Chinese_text))\n",
    "    print(nlp.ner(Chinese_text))\n",
    "    print(nlp.parse(Chinese_text))\n",
    "    print(nlp.dependency_parse(Chinese_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 英文文档分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\19843\\\\Desktop\\\\natural_language_processing\\\\Experiment2\\\\English.txt\", 'r') as f:\n",
    "    English_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Trump', 'was', 'born', 'and', 'raised', 'in', 'the', 'New', 'York', 'City', 'borough', 'of', 'Queens', 'and', 'received', 'an', 'economics', 'degree', 'from', 'the', 'Wharton', 'School', '.'], ['He', 'was', 'appointed', 'president', 'of', 'his', 'family', \"'s\", 'real', 'estate', 'business', 'in', '1971', ',', 'renamed', 'it', 'The', 'Trump', 'Organization', ',', 'and', 'expanded', 'it', 'from', 'Queens', 'and', 'Brooklyn', 'into', 'Manhattan', '.'], ['The', 'company', 'built', 'or', 'renovated', 'skyscrapers', ',', 'hotels', ',', 'casinos', ',', 'and', 'golf', 'courses', '.'], ['Trump', 'later', 'started', 'various', 'side', 'ventures', ',', 'including', 'licensing', 'his', 'name', 'for', 'real', 'estate', 'and', 'consumer', 'products', '.'], ['He', 'managed', 'the', 'company', 'until', 'his', '2017', 'inauguration', '.'], ['He', 'co-authored', 'several', 'books', ',', 'including', 'The', 'Art', 'of', 'the', 'Deal', '.'], ['He', 'owned', 'the', 'Miss', 'Universe', 'and', 'Miss', 'USA', 'beauty', 'pageants', 'from', '1996', 'to', '2015', ',', 'and', 'he', 'produced', 'and', 'hosted', 'The', 'Apprentice', ',', 'a', 'reality', 'television', 'show', ',', 'from', '2003', 'to', '2015', '.'], ['Forbes', 'estimates', 'his', 'net', 'worth', 'to', 'be', '$', '3.1', 'billion', '.']]\n",
      "['Trump', 'was', 'born', 'and', 'raised', 'in', 'the', 'New', 'York', 'City', 'borough', 'of', 'Queens', 'and', 'received', 'an', 'economics', 'degree', 'from', 'the', 'Wharton', 'School', '.', 'He', 'was', 'appointed', 'president', 'of', 'his', 'family', \"'s\", 'real', 'estate', 'business', 'in', '1971', ',', 'renamed', 'it', 'The', 'Trump', 'Organization', ',', 'and', 'expanded', 'it', 'from', 'Queens', 'and', 'Brooklyn', 'into', 'Manhattan', '.', 'The', 'company', 'built', 'or', 'renovated', 'skyscrapers', ',', 'hotels', ',', 'casinos', ',', 'and', 'golf', 'courses', '.', 'Trump', 'later', 'started', 'various', 'side', 'ventures', ',', 'including', 'licensing', 'his', 'name', 'for', 'real', 'estate', 'and', 'consumer', 'products', '.', 'He', 'managed', 'the', 'company', 'until', 'his', '2017', 'inauguration', '.', 'He', 'co-authored', 'several', 'books', ',', 'including', 'The', 'Art', 'of', 'the', 'Deal', '.', 'He', 'owned', 'the', 'Miss', 'Universe', 'and', 'Miss', 'USA', 'beauty', 'pageants', 'from', '1996', 'to', '2015', ',', 'and', 'he', 'produced', 'and', 'hosted', 'The', 'Apprentice', ',', 'a', 'reality', 'television', 'show', ',', 'from', '2003', 'to', '2015', '.', 'Forbes', 'estimates', 'his', 'net', 'worth', 'to', 'be', '$', '3.1', 'billion', '.']\n",
      "[('Trump', 'NNP'), ('was', 'VBD'), ('born', 'VBN'), ('and', 'CC'), ('raised', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('New', 'NNP'), ('York', 'NNP'), ('City', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#先分句再分词\n",
    "sents = nltk.sent_tokenize(English_text)\n",
    "word = []\n",
    "for sent in sents:\n",
    "    word.append(nltk.word_tokenize(sent))\n",
    "print(word)\n",
    "\n",
    "#分词\n",
    "text = nltk.word_tokenize(English_text)\n",
    "print(text)\n",
    "#词性标注\n",
    "tagged = nltk.pos_tag(text)\n",
    "print (tagged[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump\n",
      "was\n",
      "born\n",
      "and\n",
      "raised\n",
      "in\n",
      "the\n",
      "New\n",
      "York\n",
      "City\n",
      "borough\n",
      "of\n",
      "Queens\n",
      "and\n",
      "received\n",
      "an\n",
      "economics\n",
      "degree\n",
      "from\n",
      "the\n",
      "Wharton\n",
      "School\n",
      ".\n",
      "He\n",
      "was\n",
      "appointed\n",
      "president\n",
      "of\n",
      "his\n",
      "family\n",
      "'s\n",
      "real\n",
      "estate\n",
      "business\n",
      "in\n",
      "1971\n",
      ",\n",
      "renamed\n",
      "it\n",
      "The\n",
      "Trump\n",
      "Organization\n",
      ",\n",
      "and\n",
      "expanded\n",
      "it\n",
      "from\n",
      "Queens\n",
      "and\n",
      "Brooklyn\n",
      "into\n",
      "Manhattan\n",
      ".\n",
      "The\n",
      "company\n",
      "built\n",
      "or\n",
      "renovated\n",
      "skyscrapers\n",
      ",\n",
      "hotels\n",
      ",\n",
      "casinos\n",
      ",\n",
      "and\n",
      "golf\n",
      "courses\n",
      ".\n",
      "Trump\n",
      "later\n",
      "started\n",
      "various\n",
      "side\n",
      "ventures\n",
      ",\n",
      "including\n",
      "licensing\n",
      "his\n",
      "name\n",
      "for\n",
      "real\n",
      "estate\n",
      "and\n",
      "consumer\n",
      "products\n",
      ".\n",
      "He\n",
      "managed\n",
      "the\n",
      "company\n",
      "until\n",
      "his\n",
      "2017\n",
      "inauguration\n",
      ".\n",
      "He\n",
      "co\n",
      "-\n",
      "authored\n",
      "several\n",
      "books\n",
      ",\n",
      "including\n",
      "The\n",
      "Art\n",
      "of\n",
      "the\n",
      "Deal\n",
      ".\n",
      "He\n",
      "owned\n",
      "the\n",
      "Miss\n",
      "Universe\n",
      "and\n",
      "Miss\n",
      "USA\n",
      "beauty\n",
      "pageants\n",
      "from\n",
      "1996\n",
      "to\n",
      "2015\n",
      ",\n",
      "and\n",
      "he\n",
      "produced\n",
      "and\n",
      "hosted\n",
      "The\n",
      "Apprentice\n",
      ",\n",
      "a\n",
      "reality\n",
      "television\n",
      "show\n",
      ",\n",
      "from\n",
      "2003\n",
      "to\n",
      "2015\n",
      ".\n",
      "Forbes\n",
      "estimates\n",
      "his\n",
      "net\n",
      "worth\n",
      "to\n",
      "be\n",
      "$\n",
      "3.1\n",
      "billion\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(English_text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize: ['Trump', 'was', 'born', 'and', 'raised', 'in', 'the', 'New', 'York', 'City', 'borough', 'of', 'Queens', 'and', 'received', 'an', 'economics', 'degree', 'from', 'the', 'Wharton', 'School', '.', 'He', 'was', 'appointed', 'president', 'of', 'his', 'family', \"'s\", 'real', 'estate', 'business', 'in', '1971', ',', 'renamed', 'it', 'The', 'Trump', 'Organization', ',', 'and', 'expanded', 'it', 'from', 'Queens', 'and', 'Brooklyn', 'into', 'Manhattan', '.', 'The', 'company', 'built', 'or', 'renovated', 'skyscrapers', ',', 'hotels', ',', 'casinos', ',', 'and', 'golf', 'courses', '.', 'Trump', 'later', 'started', 'various', 'side', 'ventures', ',', 'including', 'licensing', 'his', 'name', 'for', 'real', 'estate', 'and', 'consumer', 'products', '.', 'He', 'managed', 'the', 'company', 'until', 'his', '2017', 'inauguration', '.', 'He', 'co-authored', 'several', 'books', ',', 'including', 'The', 'Art', 'of', 'the', 'Deal', '.', 'He', 'owned', 'the', 'Miss', 'Universe', 'and', 'Miss', 'USA', 'beauty', 'pageants', 'from', '1996', 'to', '2015', ',', 'and', 'he', 'produced', 'and', 'hosted', 'The', 'Apprentice', ',', 'a', 'reality', 'television', 'show', ',', 'from', '2003', 'to', '2015', '.', 'Forbes', 'estimates', 'his', 'net', 'worth', 'to', 'be', '$', '3.1', 'billion', '.']\n",
      "Part of Speech: [('Guangdong', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('Foreign', 'NNP'), ('Studies', 'NNPS'), ('is', 'VBZ'), ('located', 'JJ'), ('in', 'IN'), ('Guangzhou', 'NNP'), ('.', '.')]\n",
      "Named Entities: [('Guangdong', 'ORGANIZATION'), ('University', 'ORGANIZATION'), ('of', 'ORGANIZATION'), ('Foreign', 'ORGANIZATION'), ('Studies', 'ORGANIZATION'), ('is', 'O'), ('located', 'O'), ('in', 'O'), ('Guangzhou', 'CITY'), ('.', 'O')]\n",
      "Constituency Parsing: (ROOT\n",
      "  (S\n",
      "    (NP\n",
      "      (NP (NNP Guangdong) (NNP University))\n",
      "      (PP (IN of)\n",
      "        (NP (NNP Foreign) (NNPS Studies))))\n",
      "    (VP (VBZ is)\n",
      "      (ADJP (JJ located)\n",
      "        (PP (IN in)\n",
      "          (NP (NNP Guangzhou)))))\n",
      "    (. .)))\n",
      "Dependency Parsing: [('ROOT', 0, 7), ('compound', 2, 1), ('nsubjpass', 7, 2), ('case', 5, 3), ('compound', 5, 4), ('nmod', 2, 5), ('auxpass', 7, 6), ('case', 9, 8), ('nmod', 7, 9), ('punct', 7, 10)]\n"
     ]
    }
   ],
   "source": [
    "# Simple usage\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = StanfordCoreNLP(r'C:\\Users\\19843\\Desktop\\natural_language_processing\\stanford-corenlp-full-2018-10-05')\n",
    "\n",
    "print('Tokenize:', nlp.word_tokenize(English_text))\n",
    "print('Part of Speech:', nlp.pos_tag(sentence))\n",
    "print('Named Entities:', nlp.ner(sentence))\n",
    "print('Constituency Parsing:', nlp.parse(sentence))\n",
    "print ('Dependency Parsing:', nlp.dependency_parse(sentence))\n",
    "\n",
    "nlp.close() # Do not forget to close! The backend server will consume a lot memery."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
